{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-EBYTTGJTyi",
        "outputId": "c94c149a-f18c-4f69-a774-b27386a82552"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: /home/lixc/anaconda3/envs/pytorch/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "Requirement already satisfied: transformers in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (22.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: fsspec in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lixc/anaconda3/envs/pytorch/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "# Importing stock ml libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU0gY6JuH2JF",
        "outputId": "e608a277-0549-4622-993c-a2a42d9c1792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad0iIV1Vo2fw",
        "outputId": "ad75c7e4-8cb1-4b0a-f9d2-c30c58466e99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-07 22:09:54.028608: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-07 22:09:54.717604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-07 22:09:55.808596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:55.808837: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:55.812598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:55.812791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:55.812970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:55.813145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:59.230929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:59.231228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:59.231435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:59.231631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:59.231824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:59.232044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 19508 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
            "2023-11-07 22:09:59.232581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-07 22:09:59.232748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:1 with 4960 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:0b:00.0, compute capability: 6.1\n"
          ]
        }
      ],
      "source": [
        "#http://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "#https://github.com/abhimishra91/pytorch-tutorials/blob/master/lecture_08_a.ipynb\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtebFd8_pMYF",
        "outputId": "cf4d0f73-37e1-4c3d-d8f6-4313518999c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 2 GPU(s) available.\n",
            "We will use the GPU: NVIDIA GeForce RTX 3090\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PBsnUI_WkdxZ"
      },
      "outputs": [],
      "source": [
        "# Importing stock ml libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "097ec1c3-9cb7-4214-c8b4-a8f70f00091f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>Rotation invariance and translation invarian...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>We introduce and develop the notion of spher...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                              TITLE  \\\n",
              "0   1        Reconstructing Subject-Specific Effect Maps   \n",
              "1   2                 Rotation Invariance Neural Network   \n",
              "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
              "3   4  A finite element approximation for the stochas...   \n",
              "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
              "\n",
              "                                            ABSTRACT  Computer Science  \\\n",
              "0    Predictive models allow subject-specific inf...                 1   \n",
              "1    Rotation invariance and translation invarian...                 1   \n",
              "2    We introduce and develop the notion of spher...                 0   \n",
              "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
              "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
              "\n",
              "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
              "0        0            0           0                     0   \n",
              "1        0            0           0                     0   \n",
              "2        0            1           0                     0   \n",
              "3        0            1           0                     0   \n",
              "4        0            0           1                     0   \n",
              "\n",
              "   Quantitative Finance  \n",
              "0                     0  \n",
              "1                     0  \n",
              "2                     0  \n",
              "3                     0  \n",
              "4                     0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data_path = '/home/lixc/Downloads/multilabel/train.csv'\n",
        "destination_folder = '/home/lixc/Downloads/multilabel/'\n",
        "\n",
        "df_raw =  pd.read_csv(raw_data_path)\n",
        "\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cioR1TXp-L5",
        "outputId": "442a744e-617e-4c52-98cf-62fbbd135a3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20972, 9)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwzNSvpwjzoi",
        "outputId": "ab75e7c8-4c96-4427-fe34-4f0a419f4521"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['ID', 'TITLE', 'ABSTRACT', 'Computer Science', 'Physics', 'Mathematics',\n",
              "       'Statistics', 'Quantitative Biology', 'Quantitative Finance'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BPv89FDkKhyO"
      },
      "outputs": [],
      "source": [
        "df_raw['target_list'] = df_raw[['Computer Science', 'Physics', 'Mathematics',\n",
        "       'Statistics', 'Quantitative Biology', 'Quantitative Finance']].values.tolist()\n",
        "testlist = df_raw[['Computer Science', 'Physics', 'Mathematics',\n",
        "       'Statistics', 'Quantitative Biology', 'Quantitative Finance']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1Yt7JD9Kshv",
        "outputId": "b283560b-72f5-45ce-b441-cd0ce5749a6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 1, 0, 0],\n",
              "       [0, 0, 1, 1, 0, 0]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "fC3EkEvnL9SX",
        "outputId": "cfb46e24-2c03-40ec-b726-cc3b247d9685"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "      <th>target_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>Rotation invariance and translation invarian...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>We introduce and develop the notion of spher...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                              TITLE  \\\n",
              "0   1        Reconstructing Subject-Specific Effect Maps   \n",
              "1   2                 Rotation Invariance Neural Network   \n",
              "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
              "3   4  A finite element approximation for the stochas...   \n",
              "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
              "\n",
              "                                            ABSTRACT  Computer Science  \\\n",
              "0    Predictive models allow subject-specific inf...                 1   \n",
              "1    Rotation invariance and translation invarian...                 1   \n",
              "2    We introduce and develop the notion of spher...                 0   \n",
              "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
              "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
              "\n",
              "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
              "0        0            0           0                     0   \n",
              "1        0            0           0                     0   \n",
              "2        0            1           0                     0   \n",
              "3        0            1           0                     0   \n",
              "4        0            0           1                     0   \n",
              "\n",
              "   Quantitative Finance         target_list  \n",
              "0                     0  [1, 0, 0, 0, 0, 0]  \n",
              "1                     0  [1, 0, 0, 0, 0, 0]  \n",
              "2                     0  [0, 0, 1, 0, 0, 0]  \n",
              "3                     0  [0, 0, 1, 0, 0, 0]  \n",
              "4                     0  [1, 0, 0, 1, 0, 0]  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "mxkpdxT3sbrB",
        "outputId": "cf269250-6487-42d1-faf7-45f4f78c7c6c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "      <th>target_list</th>\n",
              "      <th>WORD_COUNT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>Rotation invariance and translation invarian...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>We introduce and develop the notion of spher...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 1, 0, 0]</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                              TITLE  \\\n",
              "0   1        Reconstructing Subject-Specific Effect Maps   \n",
              "1   2                 Rotation Invariance Neural Network   \n",
              "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
              "3   4  A finite element approximation for the stochas...   \n",
              "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
              "\n",
              "                                            ABSTRACT  Computer Science  \\\n",
              "0    Predictive models allow subject-specific inf...                 1   \n",
              "1    Rotation invariance and translation invarian...                 1   \n",
              "2    We introduce and develop the notion of spher...                 0   \n",
              "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
              "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
              "\n",
              "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
              "0        0            0           0                     0   \n",
              "1        0            0           0                     0   \n",
              "2        0            1           0                     0   \n",
              "3        0            1           0                     0   \n",
              "4        0            0           1                     0   \n",
              "\n",
              "   Quantitative Finance         target_list  WORD_COUNT  \n",
              "0                     0  [1, 0, 0, 0, 0, 0]           4  \n",
              "1                     0  [1, 0, 0, 0, 0, 0]           4  \n",
              "2                     0  [0, 0, 1, 0, 0, 0]           8  \n",
              "3                     0  [0, 0, 1, 0, 0, 0]           9  \n",
              "4                     0  [1, 0, 0, 1, 0, 0]          20  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw['WORD_COUNT'] = df_raw['TITLE'].apply(lambda x: len(x.split()))\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "13WHpuV5svDd",
        "outputId": "10212d62-eb49-41c0-83e3-9fff4e666a29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[<AxesSubplot: title={'center': 'WORD_COUNT'}>]], dtype=object)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_raw.hist('WORD_COUNT', bins=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Et3WL12SMk6t",
        "outputId": "3afe6d80-2ef4-4a82-a007-0522aad974f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>target_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>[1, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TITLE         target_list\n",
              "0        Reconstructing Subject-Specific Effect Maps  [1, 0, 0, 0, 0, 0]\n",
              "1                 Rotation Invariance Neural Network  [1, 0, 0, 0, 0, 0]\n",
              "2  Spherical polyharmonics and Poisson kernels fo...  [0, 0, 1, 0, 0, 0]\n",
              "3  A finite element approximation for the stochas...  [0, 0, 1, 0, 0, 0]\n",
              "4  Comparative study of Discrete Wavelet Transfor...  [1, 0, 0, 1, 0, 0]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = df_raw[['TITLE', 'target_list']].copy()\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NsVjK7BSLAhb"
      },
      "outputs": [],
      "source": [
        "# Sections of config\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 16\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UtxYzTglqAQu"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.title = dataframe['TITLE']\n",
        "        self.targets = self.data.target_list\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIixjtx0kHvb",
        "outputId": "06aefc51-a5b5-4040-bd88-a4f054a4f678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FULL Dataset: (20972, 2)\n",
            "TRAIN Dataset: (16778, 2)\n",
            "TEST Dataset: (4194, 2)\n"
          ]
        }
      ],
      "source": [
        "train_size = 0.8\n",
        "train_dataset = df2.sample(frac=train_size,random_state=200)\n",
        "valid_dataset = df2.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df2.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(valid_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "validation_set = CustomDataset(valid_dataset, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xfWeV3rXkxdv"
      },
      "outputs": [],
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "validation_loader = DataLoader(validation_set, **test_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17fHLHcEkOfy",
        "outputId": "59d14d91-9f8f-43c7-e6c8-95cd14daefaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(525, 132)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(training_loader), len(validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DegHNyIEQxB2"
      },
      "outputs": [],
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil\n",
        "# bert to get the final output for the model.\n",
        "\n",
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into\n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # return model, optimizer, epoch value, min validation loss\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vumYCoWMFxzn",
        "outputId": "cd89e7b2-e5fd-46d2-912b-fdf474ee9d0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 6)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        #_, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "        outputs = self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "        output_1 = outputs.last_hidden_state\n",
        "        output_2 = self.l2(output_1)\n",
        "        output = self.l3(output_2)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7B9Eit5NmV1F"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtsVVkR9FfG1",
        "outputId": "2ecd8854-e632-4515-b928-600b0baf8f4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "525"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(training_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Cjg5UbDSMBhq"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into\n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # return model, optimizer, epoch value, min validation loss\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xMHd3FnhMTnd"
      },
      "outputs": [],
      "source": [
        "import shutil, sys\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "E1iV-0MAQoGS"
      },
      "outputs": [],
      "source": [
        "#to use as global variables\n",
        "val_targets=[]\n",
        "val_outputs=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kekAnp0d-EHv"
      },
      "outputs": [],
      "source": [
        "#this is joe method\n",
        "#https://towardsdatascience.com/how-to-save-and-load-a-model-in-pytorch-with-a-complete-example-c2920e617dee\n",
        "def train_model(start_epochs,  n_epochs, valid_loss_min_input,\n",
        "                training_loader, validation_loader, model,\n",
        "                optimizer, checkpoint_path, best_model_path):\n",
        "\n",
        "  # initialize tracker for minimum validation loss\n",
        "  valid_loss_min = valid_loss_min_input\n",
        "\n",
        "\n",
        "  for epoch in range(start_epochs, n_epochs+1):\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    print('############# Epoch {}: Training Start   #############'.format(epoch))\n",
        "    for batch_idx, data in enumerate(training_loader):\n",
        "        #print('yyy epoch', batch_idx)\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        #if batch_idx%5000==0:\n",
        "         #   print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print('before loss data in training', loss.item(), train_loss)\n",
        "        train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
        "        #print('after loss data in training', loss.item(), train_loss)\n",
        "\n",
        "    print('############# Epoch {}: Training End     #############'.format(epoch))\n",
        "\n",
        "    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n",
        "    ######################\n",
        "    # validate the model #\n",
        "    ######################\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, data in enumerate(validation_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
        "            val_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "      print('############# Epoch {}: Validation End     #############'.format(epoch))\n",
        "      # calculate average losses\n",
        "      #print('before cal avg train loss', train_loss)\n",
        "      train_loss = train_loss/len(training_loader)\n",
        "      valid_loss = valid_loss/len(validation_loader)\n",
        "      # print training/validation statistics\n",
        "      print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "\n",
        "      # create checkpoint variable and add important data\n",
        "      checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': valid_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "      }\n",
        "\n",
        "        # save checkpoint\n",
        "      save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "\n",
        "      ## TODO: save the model if validation loss has decreased\n",
        "      if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "        # save checkpoint as best model\n",
        "        save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "    print('############# Epoch {}  Done   #############\\n'.format(epoch))\n",
        "\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "jNpzkTTHKYBV",
        "outputId": "69ea0950-ca85-4007-93b2-e3c2bbd577a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "############# Epoch 1: Training Start   #############\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Target size (torch.Size([32, 6])) must be the same as input size (torch.Size([32, 16, 6]))",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_61638/1203379894.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m trained_model = train_model(1, 4, np.Inf, training_loader, validation_loader, model,\n\u001b[0m\u001b[1;32m     10\u001b[0m                       optimizer,checkpoint_path,best_model)\n",
            "\u001b[0;32m/tmp/ipykernel_61638/1247571960.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(start_epochs, n_epochs, valid_loss_min_input, training_loader, validation_loader, model, optimizer, checkpoint_path, best_model_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#if batch_idx%5000==0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m          \u001b[0;31m#   print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_61638/12964138.py\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(outputs, targets)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3160\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([32, 6])) must be the same as input size (torch.Size([32, 16, 6]))"
          ]
        }
      ],
      "source": [
        "'''start_epochs,  n_epochs, valid_loss_min_input,\n",
        "                training_loader, validation_loader, model, optimizer,\n",
        "                checkpoint_path, best_model_path):\n",
        "'''\n",
        "checkpoint_path = '/home/lixc/Downloads/multilabel/current_checkpoint.pt'\n",
        "best_model = '/home/lixc/Downloads/multilabel/best_model/best_model.pt'\n",
        "\n",
        "\n",
        "trained_model = train_model(1, 4, np.Inf, training_loader, validation_loader, model,\n",
        "                      optimizer,checkpoint_path,best_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIK5GAYiVRtD"
      },
      "outputs": [],
      "source": [
        "#fin_outputs\n",
        "#print(fin_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJQRHd7VVMap"
      },
      "outputs": [],
      "source": [
        "val_preds = (np.array(val_outputs) > 0.5).astype(int)\n",
        "val_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UewEZHwJdB-G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooNjD4uunkzY"
      },
      "outputs": [],
      "source": [
        "def do_training(epoch):\n",
        "   ######################\n",
        "    # train the model #\n",
        "    ######################\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%5000==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MCmmj1UokUA"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    do_training(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpITnBlEqZ0V"
      },
      "outputs": [],
      "source": [
        "def do_validation(dataloader):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(dataloader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keZ7oF5EvT3R"
      },
      "outputs": [],
      "source": [
        "outputs, targets = do_validation(validation_loader)\n",
        "outputs = np.array(outputs) >= 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA1rUfS4LADg"
      },
      "outputs": [],
      "source": [
        "val_preds = (np.array(outputs) > 0.5).astype(int)\n",
        "val_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8QtubTPCwC0"
      },
      "outputs": [],
      "source": [
        "accuracy = metrics.accuracy_score(val_targets, val_preds)\n",
        "f1_score_micro = metrics.f1_score(val_targets, val_preds, average='micro')\n",
        "f1_score_macro = metrics.f1_score(val_targets, val_preds, average='macro')\n",
        "print(f\"Accuracy Score = {accuracy}\")\n",
        "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12vfrgbBPexJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix as mcm, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JYJdgCOQwo5"
      },
      "outputs": [],
      "source": [
        "cm_labels = ['Computer Science', 'Physics', 'Mathematics',\n",
        "       'Statistics', 'Quantitative Biology', 'Quantitative Finance']\n",
        "\n",
        "cm = mcm(val_targets, val_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idoyZabwTQN4"
      },
      "outputs": [],
      "source": [
        "print(classification_report(val_targets, val_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qABoNG6cOsHN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize=14):\n",
        "\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes)\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    axes.set_xlabel('True label')\n",
        "    axes.set_ylabel('Predicted label')\n",
        "    axes.set_title(\"Confusion Matrix for the class - \" + class_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIQCcrQhVX6n"
      },
      "outputs": [],
      "source": [
        "#print_confusion_matrix(mcm(targets, val_preds),class_label=labels, class_names=labels)\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, ax = plt.subplots(3, 2, figsize=(12, 7))\n",
        "for axes, cfs_matrix, label in zip(ax.flatten(), cm, cm_labels):\n",
        "  print_confusion_matrix(cfs_matrix, axes, label, [\"1\", \"0\"])\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNy8Xh4TwGqV"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ7m8VMcwJMO"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('/content/drive/My Drive/NLP/ResearchArticlesClassification/Dataset/test.csv')\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVXeSJ70-_ET"
      },
      "outputs": [],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhh7CJOiwQHb"
      },
      "outputs": [],
      "source": [
        "class PrepForPredictionDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.title = dataframe['TITLE']\n",
        "        #self.targets = self.data.target_list\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "           # 'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0XPefVlwt9k"
      },
      "outputs": [],
      "source": [
        "testing_set = PrepForPredictionDataset(test_df, tokenizer, MAX_LEN)\n",
        "testing_set[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CfA8KVAwv1i"
      },
      "outputs": [],
      "source": [
        "testing_loader = DataLoader(testing_set, **test_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAJmBQExxArD"
      },
      "outputs": [],
      "source": [
        "def do_prediction(loader):\n",
        "    model.eval()\n",
        "\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            #targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            #fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3L3dr6MyYAF"
      },
      "outputs": [],
      "source": [
        "pred_outputs = do_prediction(testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTNpLdLGAzul"
      },
      "outputs": [],
      "source": [
        "type(pred_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SPQHwmcCKhL"
      },
      "outputs": [],
      "source": [
        "pred_outputs = (np.array(pred_outputs) >= 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03-gtrBKC5J1"
      },
      "outputs": [],
      "source": [
        "pred_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47rH-WAm0A5B"
      },
      "outputs": [],
      "source": [
        "df_raw.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0grsQS70yuzc"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "computer_list = []\n",
        "phy_list = []\n",
        "math_list = []\n",
        "stat_list = []\n",
        "bio_list = []\n",
        "finance_list = []\n",
        "count = 0\n",
        "for i in outputs[1]:\n",
        "  computer_list.append(int(i[0]))\n",
        "  phy_list.append(int(i[1]))\n",
        "  math_list.append(int(i[2]))\n",
        "  stat_list.append(int(i[3]))\n",
        "  bio_list.append(int(i[4]))\n",
        "  finance_list.append(int(i[5]))\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfWBHreW5Fqf"
      },
      "outputs": [],
      "source": [
        "preds_df = pd.DataFrame(pred_outputs, columns =['Computer Science', 'Physics', 'Mathematics',\n",
        "       'Statistics', 'Quantitative Biology', 'Quantitative Finance'])\n",
        "preds_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ahO0GRn8T_G"
      },
      "outputs": [],
      "source": [
        "preds_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfpskv4C0zUk"
      },
      "outputs": [],
      "source": [
        "df_concat = pd.concat([test_df, preds_df], axis=1)\n",
        "df_concat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aypb1kiM64Pv"
      },
      "outputs": [],
      "source": [
        "b = df_concat[['ID','Computer Science', 'Physics', 'Mathematics',\n",
        "       'Statistics', 'Quantitative Biology', 'Quantitative Finance']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMEiG5Qw7GiD"
      },
      "outputs": [],
      "source": [
        "b.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9_dNtA17Kiz"
      },
      "outputs": [],
      "source": [
        "b.to_csv('/content/drive/My Drive/NLP/ResearchArticlesClassification/Outputs/titles_only.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfjyZx8b7QKh"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iojqQckLgh6v"
      },
      "outputs": [],
      "source": [
        "files.download('/content/drive/My Drive/NLP/ResearchArticlesClassification/Outputs/titles_only.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AwR4Y_MgoBz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
